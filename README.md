# Desafio Stone: Data Engineer

## ğŸ“Œ VisÃ£o Geral
Este projeto tem como objetivo processar os dados abertos da Receita Federal do Brasil sobre empresas e sÃ³cios, seguindo o modelo de camadas **Bronze, Silver e Gold** para transformaÃ§Ã£o e estruturaÃ§Ã£o dos dados. O ambiente Ã© totalmente containerizado com Docker e utiliza PostgreSQL para armazenar os resultados finais.

Os dados sÃ£o extraÃ­dos da URL oficial:
ğŸ”— [Receita Federal - Dados Abertos](https://dados.gov.br/dados/conjuntos-dados/cadastro-nacional-da-pessoa-juridica---cnpj)

## ğŸ› ï¸ Tecnologias Utilizadas
- **Python 3.11**
- **PostgreSQL 17**
- **Pandas**
- **SQLAlchemy**
- **Docker & Docker Compose**
- **TQDM**
- **Python-Dateutil**

## ğŸ“Œ Estrutura de Arquivos

```
stone/
â”œâ”€â”€ data/                 # DiretÃ³rio para armazenamento de dados (ex.: JSON de entrada)
â”œâ”€â”€ src/                  # CÃ³digo-fonte principal
â”‚   â”œâ”€â”€ etl.py            # Script ETL para processar e carregar os dados
â”‚   â”œâ”€â”€ database.py       # ConfiguraÃ§Ã£o e conexÃ£o com o banco de dados PostgreSQL
â”‚   â”œâ”€â”€ transform.py      # FunÃ§Ãµes de transformaÃ§Ã£o de dados
â”‚   â””â”€â”€ utils.py          # FunÃ§Ãµes utilitÃ¡rias
â”œâ”€â”€ Dockerfile            # ConfiguraÃ§Ã£o do container Docker
â”œâ”€â”€ docker-compose.yml    # OrquestraÃ§Ã£o com Docker Compose
â”œâ”€â”€ requirements.txt      # DependÃªncias do projeto
â””â”€â”€ README.md             # DocumentaÃ§Ã£o do projeto
```

## ğŸ“Š Estrutura da Tabela Final (Gold)

A tabela gerada pelo processo ETL possui o seguinte esquema:

| Nome da Coluna        | Tipo de Dado | DescriÃ§Ã£o                                                                 |
|-----------------------|--------------|---------------------------------------------------------------------------|
| cnpj                 | string       | ContÃ©m o nÃºmero de inscriÃ§Ã£o no CNPJ (Cadastro Nacional da Pessoa JurÃ­dica). |
| qtde_socios          | int          | NÃºmero de sÃ³cios participantes no CNPJ.                                  |
| flag_socio_estrangeiro | boolean     | **True**: ContÃ©m pelo menos 1 sÃ³cio estrangeiro.<br>**False**: NÃ£o contÃ©m sÃ³cios estrangeiros. |
| doc_alvo             | boolean      | **True**: Porte da empresa = 03 e qtde_socios > 1.<br>**False**: Outros. |

## InstruÃ§Ãµes para ExecuÃ§Ã£o

### PrÃ©-requisitos

- [Docker](https://www.docker.com/) e [Docker Compose](https://docs.docker.com/compose/) instalados.

### Passos para Executar

1. Clone o repositÃ³rio:
   ```bash
   git clone https://github.com/hugoas/stone.git
   cd stone
   ```

2. Construa e inicie os containers:
   ```bash
   docker-compose up --build
   ```

3. Acesse o container do serviÃ§o `web` para executar o script ETL:
   ```bash
   docker exec -it stone-web-1 bash
   python src/etl.py
   ```

### ConfiguraÃ§Ã£o do Banco de Dados

O banco de dados PostgreSQL Ã© configurado no serviÃ§o `db` do `docker-compose.yml`:
- Host: `db`
- UsuÃ¡rio: `postgres`
- Senha: `has2582`
- Porta: `5432`
- Banco: `postgres`

A variÃ¡vel de ambiente `DATABASE_URL` Ã© usada para conectar ao banco de dados:
```
postgresql://postgres:has2582@db:5432/postgres
```

## DependÃªncias

As dependÃªncias do projeto estÃ£o listadas no arquivo `requirements.txt`:

```
pandas
psycopg2-binary
tqdm
SQLAlchemy
python-dateutil
```

Instale as dependÃªncias usando o comando:
```bash
pip install -r requirements.txt
```

## ExplicaÃ§Ã£o do ETL

O projeto adota o modelo **MedalhÃ£o** (Bronze, Silver, Gold):

1. **Bronze (Raw):**
   - Dados crus extraÃ­dos diretamente do arquivo JSON localizado no diretÃ³rio `data/`.

2. **Silver (Refinado):**
   - Dados transformados conforme as regras de negÃ³cio fornecidas:
     - DeterminaÃ§Ã£o de `flag_socio_estrangeiro` com base na lista de sÃ³cios.
     - CÃ¡lculo do campo `doc_alvo` baseado no porte da empresa e nÃºmero de sÃ³cios.

3. **Gold (Tabelas Finais):**
   - Dados normalizados e prontos para anÃ¡lise, armazenados no banco de dados PostgreSQL.

## ObservaÃ§Ãµes

- Certifique-se de que o arquivo JSON esteja disponÃ­vel no diretÃ³rio `data/` antes de executar o ETL.
- O schema da tabela serÃ¡ criado automaticamente durante a execuÃ§Ã£o do script ETL caso ainda nÃ£o exista.

## ContribuiÃ§Ã£o

Sinta-se Ã  vontade para abrir issues ou enviar pull requests para melhorias.

---

Feito por [Hugo](https://github.com/hugoas).

